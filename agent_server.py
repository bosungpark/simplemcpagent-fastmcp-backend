import asyncio
import streamlit as st
import json
from typing import Any
from openai.types.responses import ResponseTextDeltaEvent
from agents import Agent, Runner
from agents.mcp import MCPServerStdio
from dotenv import load_dotenv
load_dotenv()

async def setup_mcp_servers():
    servers = [] 
    # mcp.json íŒŒì¼ì—ì„œ ì„¤ì • ì½ê¸°
    with open('mcp.json', 'r') as f:
        config = json.load(f)
    # êµ¬ì„±ëœ MCP ì„œë²„ë“¤ì„ ìˆœíšŒ
    for _, server_config in config.get('mcpServers', {}).items():
        mcp_server = MCPServerStdio(
            params={
                "command": server_config.get("command"),
                "args": server_config.get("args", [])
            },
            cache_tools_list=True
        )
        await mcp_server.connect()
        servers.append(mcp_server)
    return servers


async def setup_agent(mcp_servers: Any):
    agent = Agent(
        name='Assistant',
        instructions="""
        ë„ˆì˜ ì •ì²´ì„±ì€ ìœ ì €ì™€ ì±„íŒ… ê³¼ì •ì—ì„œ ìœ íŠœë¸Œì™€ ê´€ë ¨í•œ ë‚´ìš©ì— ëŒ€í•´ ë„ì›€ì„ ì¤„ ì—ì´ì „íŠ¸ ì„œë²„ì•¼. 
        ì•„ë˜ëŠ” ë„ˆì˜ í–‰ë™ê³¼ ë§íˆ¬ì— ëŒ€í•œ ì§€ì¹¨ì´ì•¼.

        1. ìœ ì €ì™€ì˜ ëª¨ë“  ëŒ€í™” ê¸°ë¡ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ì„œ ê¸°ì–µí•˜ê³  ìˆì–´. 
        2. ë§íˆ¬ëŠ” ì–¸ì œë‚˜ ìš©ìš©ì²´ë¥¼ ì‚¬ìš©í•´! (ì˜ˆì‹œ: ì•ˆë…•í•˜ì„¸ìš©! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš©?)
        3. í˜¹ì‹œë¼ë„ ëˆ„ê°€ ë„ˆì˜ ì´ë¦„ì„ ë¬¼ì–´ë³´ë©´ "AI ë°•ë³´ì„±"ì´ë¼ê³  ìš©ìš©ì²´ë¡œ ëŒ€ë‹µí•´.
        """,
        model="gpt-4o-mini", 
        mcp_servers= mcp_servers
    )
    return agent


async def process_user_message():
    mcp_servers = await setup_mcp_servers()
    mcp_agent = await setup_agent(mcp_servers)
    message_histories = st.session_state.chat_history

    result = Runner.run_streamed(mcp_agent, input=message_histories)

    response_text = ""
    placeholder = st.empty()

    async for event in result.stream_events():  # LLM ì‘ë‹µ í† í° ìŠ¤íŠ¸ë¦¬ë°
        if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
            response_text += event.data.delta or ""
            with placeholder.container():
                with st.chat_message("assistant"):
                    st.markdown(response_text)
        elif event.type == "run_item_stream_event": # ë„êµ¬ ì´ë²¤íŠ¸ì™€ ë©”ì‹œì§€ ì™„ë£Œ ì²˜ë¦¬
            item = event.item

            if item.type == "tool_call_item":
                tool_name = item.raw_item.name
                st.toast(f"ğŸ›  ë„êµ¬ í™œìš©: `{tool_name}`")


    st.session_state.chat_history.append({
        "role": "assistant",
        "content": response_text
    })
    # ëª…ì‹œì  ì¢…ë£Œ
    for server in mcp_servers:
        await server.__aexit__(None, None, None)

def main():
    # FYI. stëŠ” streamlitì€ ì›¹ ê¸°ë°˜ì˜ ëŒ€í™”í˜• ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ê°„ë‹¨í•œ UI êµ¬ì„±ì„ ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.
    st.set_page_config(page_title="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš©", page_icon=":robot_face:")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    st.title("ìœ íŠœë¸Œ mcp ì—ì´ì „íŠ¸ì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš©")
    st.caption("ë‚˜ëŠ” ìœ íŠœë¸Œì— ì—°ë™ë˜ì–´ ìˆì–´ìš©. ì£¼ì²´ì ìœ¼ë¡œ ì¼í•˜ëŠ” ì—ì´ì „íŠ¸ì—ê²Œ ë¬´ì—‡ì´ë˜ ë¬¼ì–´ë³´ì„¸ìš©!")

    for m in st.session_state.chat_history:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])
    
    # ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™” ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    user_input = st.chat_input("ëŒ€í™”ë¥¼ í•´ì£¼ì„¸ìš©")
    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        asyncio.run(process_user_message())

if __name__ == "__main__":
    main()
